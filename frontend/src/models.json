{
  "predefined_models": [
    {
      "name": "Qwen/Qwen3-4B-AWQ",
      "abbr": "qwen-3-4b-instruct-awq",
      "type": "llm",
      "description": "Qwen 3 4B Instruct (4-bit AWQ) - 6.2GB",
      "quantization": "awq",
      "max_model_len": 8192,
      "recommended_settings": {
        "gpu_memory_utilization": 0.12,
        "max_num_seqs": 5
      }
    },
    {
      "name": "TheBloke/Mistral-7B-Instruct-v0.2-AWQ",
      "abbr": "mistral7b-awq",
      "type": "llm",
      "description": "Mistral 7B v0.2 (4-bit AWQ) - 9.7GB",
      "quantization": "awq",
      "max_model_len": 8192,
      "recommended_settings": {
        "gpu_memory_utilization": 0.2,
        "max_num_seqs": 5
      }
    },
    {
      "name": "casperhansen/llama-3-8b-instruct-awq",
      "abbr": "llama-3-8b-instruct-awq",
      "type": "llm",
      "description": "Llama 3 8B Instruct (4-bit AWQ) - 9.7GB",
      "quantization": "awq",
      "max_model_len": 8192,
      "recommended_settings": {
        "gpu_memory_utilization": 0.20,
        "max_num_seqs": 5
      }
    },
    {
      "name": "gaunernst/gemma-3-4b-it-int4-awq",
      "abbr": "gemma-3-4b-instruct-awq",
      "type": "llm",
      "description": "Gemma 3 4B Instruct (4-bit AWQ)",
      "quantization": "awq",
      "max_model_len": 8192,
      "recommended_settings": {
        "gpu_memory_utilization": 0.12,
        "max_num_seqs": 5
      }
    },
    {
      "name": "BAAI/bge-large-en-v1.5",
      "abbr": "bge-large",
      "type": "embedding",
      "description": "BGE Large English embedding model",
      "max_model_len": 512,
      "recommended_settings": {
        "gpu_memory_utilization": 0.05,
        "max_num_seqs": 512
      }
    },
    {
      "name": "BAAI/bge-base-en-v1.5",
      "abbr": "bge-base",
      "type": "embedding",
      "description": "BGE Base English embedding model",
      "max_model_len": 512,
      "recommended_settings": {
        "gpu_memory_utilization": 0.05,
        "max_num_seqs": 1024
      }
    },
    {
      "name": "sentence-transformers/all-MiniLM-L6-v2",
      "abbr": "minilm",
      "type": "embedding",
      "description": "Lightweight embedding model",
      "max_model_len": 256,
      "recommended_settings": {
        "gpu_memory_utilization": 0.05,
        "max_num_seqs": 1024
      }
    },
    {
      "name": "BM-K/KoSimCSE-roberta",
      "abbr": "kosimcse-roberta",
      "type": "embedding",
      "description": "Korean-Sentence-Embedding",
      "max_model_len": 512,
      "recommended_settings": {
        "gpu_memory_utilization": 0.05,
        "max_num_seqs": 1024
      }
    },
    {
      "name": "snunlp/KR-SBERT-V40K-klueNLI-augSTS",
      "abbr": "kr-sbert",
      "type": "embedding",
      "description": "Korean sentence-transformers model",
      "max_model_len": 128,
      "recommended_settings": {
        "gpu_memory_utilization": 0.05,
        "max_num_seqs": 1024
      }
    }
  ],
  "gpu_allocation_strategy": {
    "A6000": {
      "total_vram_gb": 48,
      "suggested_combinations": [
        {
          "name": "Balanced LLM + Embeddings",
          "models": [
            {
              "abbr": "llama13b-awq",
              "vram_gb": 8
            },
            {
              "abbr": "qwen7b",
              "vram_gb": 14
            },
            {
              "abbr": "bge-large",
              "vram_gb": 2
            },
            {
              "abbr": "bge-base",
              "vram_gb": 1
            }
          ],
          "total_vram_gb": 25,
          "remaining_gb": 23
        },
        {
          "name": "Maximum LLMs",
          "models": [
            {
              "abbr": "llama8b",
              "vram_gb": 16
            },
            {
              "abbr": "mistral7b",
              "vram_gb": 14
            },
            {
              "abbr": "qwen7b",
              "vram_gb": 14
            }
          ],
          "total_vram_gb": 44,
          "remaining_gb": 4
        },
        {
          "name": "RAG Optimized",
          "models": [
            {
              "abbr": "llama13b-awq",
              "vram_gb": 8
            },
            {
              "abbr": "bge-large",
              "vram_gb": 2
            },
            {
              "abbr": "reranker-m3",
              "vram_gb": 3
            },
            {
              "abbr": "minilm",
              "vram_gb": 1
            }
          ],
          "total_vram_gb": 14,
          "remaining_gb": 34
        }
      ]
    }
  }
}